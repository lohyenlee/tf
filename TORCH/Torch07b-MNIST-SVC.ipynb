{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b08904e-e3ba-4a6e-afd8-19fbda0e15cd",
   "metadata": {},
   "source": [
    "# Neural Networks in PyTorch\n",
    "## Part 7b: A support vector classifier implemented as a neural network\n",
    "*Yen Lee Loh, 2021-9-8, 2022-11-23*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a21ce8-4036-451c-a285-ff8b4a15c603",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ade97b68-779f-40e4-a147-cdc34f1565bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn        # import torch.nn as nn\n",
    "import torchvision.datasets # In functional.py: patch PILLOW_VERSION--> __version__\n",
    "import torchvision.transforms\n",
    "#import time\n",
    "from collections.abc import Iterable\n",
    "rng = np.random.default_rng()\n",
    "np.set_printoptions (linewidth=300)\n",
    "#plt.rcParams.update ({'font.family':'monospace', 'font.size':11})\n",
    "plt.rcParams.update ({'font.family':'serif', 'font.size':13})\n",
    "\n",
    "\n",
    "def gallery(xnij, cmap='viridis', labels=None, size=1):  # size is in inches\n",
    "  '''\n",
    "  gallery(xnij)\n",
    "  \n",
    "      Display an array of grayscale images.\n",
    "  '''\n",
    "  nmax = len(xnij)\n",
    "  cols = min(20,nmax) ; rows = (nmax+cols-1)//cols\n",
    "  wspace = 0.02 ; hspace = 0.02\n",
    "  if isinstance (labels, Iterable) or labels!=None:   # if user has supplied labels\n",
    "    hspace = .35\n",
    "    \n",
    "  fig,axs = plt.subplots (rows,cols, figsize=(cols*size*(1+wspace),rows*size*(1+hspace)), gridspec_kw={'wspace':wspace,'hspace':hspace})\n",
    "  if nmax==1: axs = np.array([[axs]])\n",
    "  axs = axs.flatten()\n",
    "  for ax in axs:\n",
    "      ax.axis ('off')\n",
    "  for n in range(nmax):\n",
    "      ax = axs[n]\n",
    "      if isinstance (cmap, Iterable) and not isinstance (cmap, str):\n",
    "        c = cmap[n]\n",
    "      else:\n",
    "        c = cmap\n",
    "      ax.imshow (xnij[n], cmap=c)\n",
    "      ax.set_aspect('equal')\n",
    "      if isinstance (labels, Iterable):\n",
    "        ax.set_title (str(labels[n]))\n",
    "\n",
    "def metrics (Yn, yn):\n",
    "  '''\n",
    "  totalExamples,misclassifiedExamples,confusionMatrix = metrics (modelOutputs, trueOutputs)\n",
    "  \n",
    "      This function accepts a set of model outputs (predictions) and a set of training outputs (labels).\n",
    "      It returns various integers.  It's easiest to understand this by seeing an example.\n",
    "  '''\n",
    "  nmax = len(yn)\n",
    "  ymax = max(yn)+1\n",
    "  confmat = np.zeros ([ymax, ymax], dtype=int)   # confmat[Y][y]\n",
    "  for n in range(nmax): confmat[yn[n], Yn[n]] += 1\n",
    "  ntot = np.sum(confmat)\n",
    "  nerr = ntot - np.trace(confmat)\n",
    "  return ntot,nerr,confmat\n",
    "\n",
    "def select (inputs, outputs, classes, nT, nV, shuffle=False):\n",
    "  '''\n",
    "  xT,yT,xV,yV = select (MNISTinputs, MNISToutputs, [5,6,8], [100,100,100], [200,200,200])\n",
    "\n",
    "      Given a set of inputs and outputs, \n",
    "      construct a training set consisting of the first 100 5's, 100 6's, 100 8's, \n",
    "      and a validation set consisting of the next 200 5's, 200 6's, and 200 8's.\n",
    "      If the original set has fewer than 300 5's, 6's, or 7's, raise an exception.\n",
    "  '''\n",
    "  assert len(classes) == len(nT) and len(nT) == len(nV)\n",
    "  allT = []\n",
    "  allV = []\n",
    "  for k in range(len(classes)):\n",
    "    indices, = np.where(outputs==classes[k])\n",
    "    ntot = len(indices)\n",
    "    indices = rng.choice (indices, nT[k] + nV[k], False)    # randomly choose 300\n",
    "    indicesT,indicesV = np.split (indices, [nT[k]])\n",
    "    allT += indicesT.tolist()\n",
    "    allV += indicesV.tolist()\n",
    "    print ('For class {}, given {} examples, we chose {} for training and {} for validation. '.format(classes[k], ntot, len(indicesT), len(indicesV)))\n",
    "  if shuffle:\n",
    "    rng.shuffle (allT)\n",
    "    rng.shuffle (allV)\n",
    "  return inputs[allT], outputs[allT], inputs[allV], outputs[allV]\n",
    "\n",
    "\n",
    "\n",
    "def train(xnd, ynd, model, lossFunc, epochs=10000, learningRate=0.01, lossTarget=0.0001, reportInterval=1000):\n",
    "  '''\n",
    "  train (xnd, ynd, model, lossFunc, epochs=10000, learningRate=0.01, lossTarget=0.0001, reportInterval=1000)\n",
    "\n",
    "      xnd      a torch.Tensor representing N training inputs (which are D-vectors)\n",
    "      ynd      a torch.Tensor representing N training outputs (usually 1-vectors)\n",
    "      model    a nn.Module that accepts a set of inputs and returns a set of outputs\n",
    "      lossFunc a \n",
    "      and a validation set consisting of the next 200 5's, 200 6's, and 200 8's.\n",
    "      If the original set has fewer than 300 5's, 6's, or 7's, raise an exception.\n",
    "  '''\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "  model.train()                  # put model in training mode\n",
    "  for t in range(epochs):      # t is the epoch number\n",
    "    Ynd = model(xnd)             # uppercase Y = model prediction\n",
    "    loss = lossFunc(Ynd,ynd)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if t % reportInterval == 0 or t==epochs:\n",
    "      F = loss.item()\n",
    "      print('Training epoch {}/{}  \\t Loss = {:.4f}'.format(t, epochs, F))\n",
    "      if F < lossTarget:\n",
    "        print('Training epoch {}/{}  \\t Loss = {:.4f} < lossTarget\\n'.format(t, epochs, F))\n",
    "        return\n",
    "  print ('Warning: loss > lossTarget!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "026e5586-4900-439b-bd50-3ca05c94016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================ DOWNLOAD THE MNIST-TRAIN DATASET, WHICH CONTAINS 60000 HANDWRITTEN DIGITS\n",
    "dataset = torchvision.datasets.MNIST('MNIST-TRAIN', download=True, train=True, transform=torchvision.transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=70000, shuffle=False)\n",
    "iterator = iter(loader)\n",
    "inputs,outputs = next(iterator)  # new PyTorch syntax; old syntax was iterator.next()\n",
    "inputs = inputs.squeeze()        # get rid of unnecessary dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "406842e9-1f31-4716-9fe2-c21d454433a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available() = True\n"
     ]
    }
   ],
   "source": [
    "print (\"torch.cuda.is_available() =\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be3188-a04d-4ba8-8e20-cc0248c4e618",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 2. Load a digit pair from the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f8fabab7-153d-4914-83b1-bf079dc20ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class 6, given 5918 examples, we chose 2500 for training and 2500 for validation. \n",
      "For class 9, given 5949 examples, we chose 2500 for training and 2500 for validation. \n"
     ]
    }
   ],
   "source": [
    "class0,class1 = 6,9     #3,8     #1,5\n",
    "xnijT,ynT,xnijV,ynV = select (inputs, outputs, [class0,class1], [2500,2500], [2500,2500], shuffle=True) \n",
    "xndT = xnijT.flatten (1,-1) ; yndT = (ynT.reshape (-1,1) - class0) / (class1-class0)\n",
    "xndV = xnijV.flatten (1,-1) ; yndV = (ynV.reshape (-1,1) - class0) / (class1-class0)\n",
    "_,imax,jmax = xnijT.shape\n",
    "_,dmax = xndT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b593e67f-3c2a-412f-b1e4-1eea54e737a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 3. Train SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e763295-90b6-43e1-880b-fc1c5f692878",
   "metadata": {},
   "source": [
    "We may implement a support vector classifier as a PyTorch neural network as follows.  \n",
    "- Suppose we are given an input vector $\\underline{\\mathbf{x}}$ and an output label $y=\\pm 1$.\n",
    "- The linear predictor is $u = \\underline{\\mathbf{w}} \\cdot \\underline{\\mathbf{x}} + b$.\n",
    "- We will consider the output of the SVC to be $Y = u$.\n",
    "- The decision function of the SVC is $Y_\\text{mp} = \\text{sgn} u$.\n",
    "- The loss function is $F=\\text{ReLU}(1-yY)$.\n",
    "\n",
    "There are a couple of quirks to watch out for:\n",
    "- When constructing the training outputs we have used the convention that $y\\in \\{0,1\\}$.\n",
    "- Therefore, in our implementation, the loss function should actually be $F=\\text{ReLU} \\big( 1-(2y-1)Y \\big)$.\n",
    "- To keep things general, we actually work with 1-dimensional tensors $\\{y_d\\}$ and $\\{Y_d\\}$.  We need to sum over the $d$ index to get a scalar.\n",
    "  In other words, $F=\\text{ReLU} \\big( 1 -  \\sum_{d=1}^1  (2y_d-1)Y_d \\big)$.\n",
    "- When operating on a batch of data, the loss function should be summed over data items as $F=\\sum_n \\text{ReLU} \\big( 1-(2y_n-1)Y_n \\big)$.\n",
    "- Putting everything together, the loss function should be $F=\\sum_n \\text{ReLU} \\big( 1- \\sum_{d=1}^1 (2y_n-1)Y_n \\big)$.\n",
    "- The decision function should be $Y_\\text{mp} = (\\text{sgn} u + 1)/2$, so that $Y_\\text{mp} \\in \\{0,1\\}$.\n",
    "\n",
    "We can implement the model and loss function very easily using PyTorch's building blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bc89ee23-44e7-4c8d-8ab3-93c7b5f99841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0/10000  \t Loss = 5118.7090\n",
      "Training epoch 1000/10000  \t Loss = 0.0000\n",
      "Training epoch 1000/10000  \t Loss = 0.0000 < lossTarget\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#================ TRAIN SVC ON CPU\n",
    "model    = nn.Linear(dmax,1)\n",
    "lossFunc = lambda Ynd, ynd: nn.functional.relu (1 - torch.sum((2*ynd-1) * Ynd, axis=1) ).sum()\n",
    "train (xndT, yndT, model, lossFunc, learningRate=0.1, reportInterval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d3b57e26-7d4e-4c0e-aaa1-20d7ef88f870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc974b56fd0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow (model.weight.reshape (28,28).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cb74eb5b-9575-45f9-8ddf-22262f74c65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear predictor u=-9.56    Model prediction Y=0  Label y=0  Loss F=0.0         \n",
      "Linear predictor u=+27.38   Model prediction Y=1  Label y=1  Loss F=0.0         \n",
      "Linear predictor u=+22.99   Model prediction Y=1  Label y=1  Loss F=0.0         \n",
      "Linear predictor u=+35.59   Model prediction Y=1  Label y=1  Loss F=0.0         \n",
      "Linear predictor u=+24.26   Model prediction Y=1  Label y=1  Loss F=0.0         \n",
      "Linear predictor u=+16.77   Model prediction Y=1  Label y=1  Loss F=0.0         \n",
      "Linear predictor u=-30.23   Model prediction Y=0  Label y=0  Loss F=0.0         \n",
      "Linear predictor u=-11.72   Model prediction Y=0  Label y=0  Loss F=0.0         \n",
      "Linear predictor u=+12.20   Model prediction Y=1  Label y=1  Loss F=0.0         \n",
      "Linear predictor u=-25.12   Model prediction Y=0  Label y=0  Loss F=0.0         \n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "  Y = model (xndT[n:n+1])\n",
    "  y = yndT[n:n+1]\n",
    "  print ('Linear predictor u={:<+8.2f} Model prediction Y={:.0f}  Label y={:.0f}  Loss F={:<12.4}'.format(Y.item(), torch.sign(Y).item()/2+1/2, y.item(), lossFunc (Y, y)    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "692dab32-9ea1-4ad9-8c69-19085a858206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error   =    0/5000 =  0.0%    Confusion matrix = [[2500, 0], [0, 2500]]\n",
      "Validation error =   25/5000 =  0.5%    Confusion matrix = [[2491, 9], [16, 2484]]\n"
     ]
    }
   ],
   "source": [
    "#================ EVALUATE ACCURACY FOR BOTH TRAINING AND VALIDATION SETS\n",
    "model.eval()             # choose evaluation mode\n",
    "YndT = model(xndT).sign()/2+1/2\n",
    "YndV = model(xndV).sign()/2+1/2\n",
    "YnT = YndT.detach().numpy().round().flatten().astype(int)  # round to either 0 or 1\n",
    "ynT = yndT.detach().numpy().flatten().astype(int)          # this is already an integer\n",
    "YnV = YndV.detach().numpy().round().flatten().astype(int)  # round to either 0 or 1\n",
    "ynV = yndV.detach().numpy().flatten().astype(int)          # this is already an integer\n",
    "\n",
    "ntot,nerr,Cnn = metrics (YnT, ynT)\n",
    "print(\"Training error   = {:4d}/{:} = {:4.1f}%    Confusion matrix = {}\".format (nerr, ntot, 100*nerr/ntot, Cnn.tolist()))\n",
    "ntot,nerr,Cnn = metrics (YnV, ynV)\n",
    "print(\"Validation error = {:4d}/{:} = {:4.1f}%    Confusion matrix = {}\".format (nerr, ntot, 100*nerr/ntot, Cnn.tolist()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
