{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f4b791-551a-4903-befb-3cf86d54c577",
   "metadata": {},
   "source": [
    "# Neural Networks in PyTorch\n",
    "## Chapter 5: Binary Classification of Multidimensional Data\n",
    "*Yen Lee Loh, 2022-12-3*\n",
    "\n",
    "The previous chapter focused on curve fitting (machine learning for functions of a single variable).\n",
    "For this and the next few chapters, we focus on binary classification (machine learning for binary functions of many variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c8f6b-335c-4a7c-8811-b76e579a4922",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 1.  Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aef155d-580e-4294-a1ed-4fdc91c370bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16ac6d0-cc36-4a16-a7d0-602ee70180c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(xnd, ynd, model, lossFunc, epochs=10000, learningRate=0.001, lossTarget=0.01, reportInterval=1000):\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "  model.train()                  # put model in training mode\n",
    "  for t in range(epochs):      # t is the epoch number\n",
    "    Ynd = model(xnd)             # uppercase Y = model prediction\n",
    "    loss = lossFunc(Ynd,ynd)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    F = loss.item()\n",
    "    if t % reportInterval == 0 or t==epochs:\n",
    "      print('Training epoch {}/{}  \\t Loss = {:.4f}'.format(t, epochs, F))\n",
    "    if F < lossTarget:\n",
    "      print('Training epoch {}/{}  \\t Loss = {:.4f} < lossTarget\\n'.format(t, epochs, F))\n",
    "      return\n",
    "  print ('Warning: loss > lossTarget!\\n')\n",
    "\n",
    "def metrics (Yn, yn):   # Yn are model outputs, yn are true outputs\n",
    "  nmax = len(yn)\n",
    "  ymax = max(yn)+1\n",
    "  confmat = np.zeros ([ymax, ymax], dtype=int)   # confmat[Y][y]\n",
    "  for n in range(nmax): confmat[yn[n], Yn[n]] += 1\n",
    "  ntot = np.sum(confmat)\n",
    "  nerr = ntot - np.trace(confmat)\n",
    "  return ntot,nerr,confmat\n",
    "\n",
    "def assess (xnd, ynd, model, lossFunc):\n",
    "  np.set_printoptions(precision=2,suppress=True,floatmode='fixed')\n",
    "  nmax = xnd.size(0)\n",
    "  #======== Feedforward\n",
    "  model.eval()               # put model in evaluation mode\n",
    "  Ynd = model(xnd)\n",
    "  loss = lossFunc(Ynd,ynd)\n",
    "  #======== Convert type\n",
    "  xnd = xnd.numpy().astype(int)                            # integer just for printing purposes\n",
    "  Yn = Ynd.detach().numpy().flatten().round().astype(int)  # round this\n",
    "  yn = ynd.detach().numpy().flatten().astype(int)\n",
    "  print ('{:10}{:>10}{:>15}'.format('input x', 'target y', 'prediction Y'))\n",
    "  for n in range(nmax):\n",
    "    print ('{:10}{:10}{:15}'.format(str(xnd[n]), yn[n], Yn[n]))\n",
    "  print ()\n",
    "  #======== Round Y\n",
    "  ntot,nerr,Cnn = metrics (Yn, yn)\n",
    "  print(\"Loss = {:.4f}      Error = {:d}/{:} = {:.1f}%       Confusion matrix = {}\".format (loss, nerr, ntot, 100*nerr/ntot, Cnn.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624ba1b0-a085-48de-a0c6-72931e832dd2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Three-way Boolean AND"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52f4d4-4961-4c48-abd5-9bf67566638f",
   "metadata": {},
   "source": [
    "Binary classification is a supervised learning problem.  We are given a dataset consisting of input vectors $\\mathbf{x}_n$ and scalar-valued outputs $y_n$ (training labels).  We wish to train a model on this data, so that the model predictions $Y_n = Y(\\mathbf{x}_n)$ match the training labels $y_n$ as closely as possible.  Since the model output is supposed to be either 0 or 1, we will generally use nn.Sigmoid() as the last layer of our neural network, because this layer gives an output between 0 and 1, which can easily be rounded to 0 or 1.\n",
    "\n",
    "For our first example, we consider a Boolean function of three Boolean variables, $y(x_0,x_1,x_2) = x_0 \\text{ AND } x_1 \\text{ AND } x_2$, where $y$ and $x_d$ are all either 0 or 1.  This function can easily be learned by a single-layer perceptron, which implements the model $Y=\\text{sigmoid} (\\mathbf{w}\\cdot\\mathbf{x} + b)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c7ae2d-c831-47e3-8d2c-e4b439066e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0/1000  \t Loss = 0.7436\n",
      "Training epoch 100/1000  \t Loss = 0.1607\n",
      "Training epoch 200/1000  \t Loss = 0.0906\n",
      "Training epoch 300/1000  \t Loss = 0.0593\n",
      "Training epoch 400/1000  \t Loss = 0.0419\n",
      "Training epoch 500/1000  \t Loss = 0.0312\n",
      "Training epoch 600/1000  \t Loss = 0.0242\n",
      "Training epoch 700/1000  \t Loss = 0.0193\n",
      "Training epoch 800/1000  \t Loss = 0.0158\n",
      "Training epoch 900/1000  \t Loss = 0.0131\n",
      "Warning: loss > lossTarget!\n",
      "\n",
      "Weight matrix =  [[7.328484  7.3260894 7.332103 ]]\n",
      "Bias vector   =  [-18.711174]\n",
      "\n",
      "input x     target y   prediction Y\n",
      "[0 0 0]            0              0\n",
      "[0 0 1]            0              0\n",
      "[0 1 0]            0              0\n",
      "[0 1 1]            0              0\n",
      "[1 0 0]            0              0\n",
      "[1 0 1]            0              0\n",
      "[1 1 0]            0              0\n",
      "[1 1 1]            1              1\n",
      "\n",
      "Loss = 0.0111      Error = 0/8 = 0.0%       Confusion matrix = [[7, 0], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "xnd      = torch.tensor([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]], dtype=torch.float32)\n",
    "ynd      = torch.tensor([[0,0,0,0,0,0,0,1]], dtype=torch.float32).T\n",
    "model    = nn.Sequential(\n",
    "            nn.Linear(xnd.size(1), ynd.size(1)),   # linear layer with 3 inputs and 1 output: nn.Linear(3,1)\n",
    "            nn.Sigmoid()                           # sigmoid function whose output lies between 0 and 1\n",
    "           )\n",
    "lossFunc = nn.BCELoss()                            # binary cross-entropy loss\n",
    "train (xnd, ynd, model, lossFunc, epochs=1000, reportInterval=100, learningRate=0.1)\n",
    "print (\"Weight matrix = \", model[0].weight.detach().numpy())\n",
    "print (\"Bias vector   = \", model[0].bias.detach().numpy())\n",
    "print ()\n",
    "assess (xnd, ynd, model, lossFunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a88636-2736-4a1a-9411-758d44668042",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Three-way Boolean XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8e252-7e2e-4d75-9dd8-5300ed6ab7bb",
   "metadata": {},
   "source": [
    "It has been proven that a SLP cannot learn the function $y(x_0,x_1,x_2) = x_0 \\text{ XOR } x_1 \\text{ XOR } x_2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5c4042-c3ed-40e5-b94c-f295513ec566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0/1000  \t Loss = 0.7012\n",
      "Training epoch 100/1000  \t Loss = 0.6931\n",
      "Training epoch 200/1000  \t Loss = 0.6931\n",
      "Training epoch 300/1000  \t Loss = 0.6931\n",
      "Training epoch 400/1000  \t Loss = 0.6931\n",
      "Training epoch 500/1000  \t Loss = 0.6931\n",
      "Training epoch 600/1000  \t Loss = 0.6931\n",
      "Training epoch 700/1000  \t Loss = 0.6931\n",
      "Training epoch 800/1000  \t Loss = 0.6931\n",
      "Training epoch 900/1000  \t Loss = 0.6931\n",
      "Warning: loss > lossTarget!\n",
      "\n",
      "Weight matrix =  [[-0.00  0.00  0.00]]\n",
      "Bias vector   =  [-0.00]\n",
      "\n",
      "input x     target y   prediction Y\n",
      "[0 0 0]            0              0\n",
      "[0 0 1]            1              0\n",
      "[0 1 0]            1              0\n",
      "[0 1 1]            0              0\n",
      "[1 0 0]            1              0\n",
      "[1 0 1]            0              0\n",
      "[1 1 0]            0              0\n",
      "[1 1 1]            1              0\n",
      "\n",
      "Loss = 0.6931      Error = 4/8 = 50.0%       Confusion matrix = [[4, 0], [4, 0]]\n"
     ]
    }
   ],
   "source": [
    "xnd      = torch.tensor([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]], dtype=torch.float32)\n",
    "ynd      = torch.tensor([[0,1,1,0,1,0,0,1]], dtype=torch.float32).T\n",
    "model    = nn.Sequential(\n",
    "            nn.Linear(xnd.size(1), ynd.size(1)),   # linear layer with 3 inputs and 1 output\n",
    "            nn.Sigmoid()                           # sigmoid function whose output lies between 0 and 1\n",
    "           )\n",
    "lossFunc = nn.BCELoss()                            # binary cross-entropy loss\n",
    "train (xnd, ynd, model, lossFunc, epochs=1000, reportInterval=100, learningRate=0.1)\n",
    "print (\"Weight matrix = \", model[0].weight.detach().numpy())\n",
    "print (\"Bias vector   = \", model[0].bias.detach().numpy())\n",
    "print ()\n",
    "assess (xnd, ynd, model, lossFunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb5cdc-7ce1-4dc3-a4d9-81c4718bab06",
   "metadata": {},
   "source": [
    "Below, we demonstrate that the XOR function can be learned by a multilayer perceptron with the structure\n",
    "\n",
    "$\\qquad(x_0,x_1,x_2)\n",
    " \\xrightarrow{linear} \\xrightarrow{sigmoid} (u_0,u_1,u_2,u_3)\n",
    " \\xrightarrow{linear} \\xrightarrow{sigmoid} (Y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447e9539-665e-485c-82fe-5d5544460d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0/1000  \t Loss = 0.6945\n",
      "Training epoch 100/1000  \t Loss = 0.0575\n",
      "Training epoch 199/1000  \t Loss = 0.0100 < lossTarget\n",
      "\n",
      "Weights in first linear layer = \n",
      " [[-6.61 -9.27  7.88]\n",
      " [-8.41 -4.60 -4.59]\n",
      " [-6.84  8.05 -9.44]\n",
      " [-8.26 -8.85 -9.34]]\n",
      "Weights in second linear layer = \n",
      " [[-7.90  9.38 -7.88 -6.25]]\n",
      "\n",
      "input x     target y   prediction Y\n",
      "[0 0 0]            0              0\n",
      "[0 0 1]            1              1\n",
      "[0 1 0]            1              1\n",
      "[0 1 1]            0              0\n",
      "[1 0 0]            1              1\n",
      "[1 0 1]            0              0\n",
      "[1 1 0]            0              0\n",
      "[1 1 1]            1              1\n",
      "\n",
      "Loss = 0.0099      Error = 0/8 = 0.0%       Confusion matrix = [[4, 0], [0, 4]]\n"
     ]
    }
   ],
   "source": [
    "xnd      = torch.tensor([[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]], dtype=torch.float32)\n",
    "ynd      = torch.tensor([[0,1,1,0,1,0,0,1]], dtype=torch.float32).T\n",
    "model    = nn.Sequential(\n",
    "            nn.Linear(3, 4),   # linear layer with 3 inputs and 4 output\n",
    "            nn.Sigmoid(),      # sigmoid function \n",
    "            nn.Linear(4, 1),   # linear layer with 4 inputs and 1 output\n",
    "            nn.Sigmoid()       # sigmoid function whose output lies between 0 and 1\n",
    "           )\n",
    "lossFunc = nn.BCELoss()        # binary cross-entropy loss\n",
    "train (xnd, ynd, model, lossFunc, epochs=1000, reportInterval=100, learningRate=0.1)\n",
    "print (\"Weights in first linear layer = \\n\", model[0].weight.detach().numpy())   # model[0].bias.detach().numpy())\n",
    "print (\"Weights in second linear layer = \\n\", model[2].weight.detach().numpy())   # model[0].bias.detach().numpy())\n",
    "print ()\n",
    "assess (xnd, ynd, model, lossFunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf551bf-fc31-47cd-adef-e197593d42f5",
   "metadata": {},
   "source": [
    "If the error above is zero, then the NN has succeeded in learning the 3-way XOR function.  However, this doesn't mean it is useful for anything, or that it has learned any transferable knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a525f-bef3-495b-8d93-58c9f2ba59b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Appendix: Using pandas to format tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13e970d-706f-4740-9517-1a74d10f0198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d5919 th {\n",
       "  font-size: 10pt;\n",
       "}\n",
       "#T_d5919_row0_col0, #T_d5919_row0_col1, #T_d5919_row0_col2, #T_d5919_row0_col3, #T_d5919_row0_col4, #T_d5919_row1_col0, #T_d5919_row1_col1, #T_d5919_row1_col2, #T_d5919_row1_col3, #T_d5919_row1_col4, #T_d5919_row2_col0, #T_d5919_row2_col1, #T_d5919_row2_col2, #T_d5919_row2_col3, #T_d5919_row2_col4, #T_d5919_row3_col0, #T_d5919_row3_col1, #T_d5919_row3_col2, #T_d5919_row3_col3, #T_d5919_row3_col4, #T_d5919_row4_col0, #T_d5919_row4_col1, #T_d5919_row4_col2, #T_d5919_row4_col3, #T_d5919_row4_col4, #T_d5919_row5_col0, #T_d5919_row5_col1, #T_d5919_row5_col2, #T_d5919_row5_col3, #T_d5919_row5_col4, #T_d5919_row6_col0, #T_d5919_row6_col1, #T_d5919_row6_col2, #T_d5919_row6_col3, #T_d5919_row6_col4, #T_d5919_row7_col0, #T_d5919_row7_col1, #T_d5919_row7_col2, #T_d5919_row7_col3, #T_d5919_row7_col4 {\n",
       "  font-size: 10pt;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d5919\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d5919_level0_col0\" class=\"col_heading level0 col0\" >x0</th>\n",
       "      <th id=\"T_d5919_level0_col1\" class=\"col_heading level0 col1\" >x1</th>\n",
       "      <th id=\"T_d5919_level0_col2\" class=\"col_heading level0 col2\" >x2</th>\n",
       "      <th id=\"T_d5919_level0_col3\" class=\"col_heading level0 col3\" >Target output y</th>\n",
       "      <th id=\"T_d5919_level0_col4\" class=\"col_heading level0 col4\" >Predicted output Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d5919_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d5919_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_d5919_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_d5919_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_d5919_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_d5919_row0_col4\" class=\"data row0 col4\" >0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5919_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d5919_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_d5919_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_d5919_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "      <td id=\"T_d5919_row1_col3\" class=\"data row1 col3\" >1</td>\n",
       "      <td id=\"T_d5919_row1_col4\" class=\"data row1 col4\" >0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5919_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d5919_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_d5919_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "      <td id=\"T_d5919_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_d5919_row2_col3\" class=\"data row2 col3\" >1</td>\n",
       "      <td id=\"T_d5919_row2_col4\" class=\"data row2 col4\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5919_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d5919_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_d5919_row3_col1\" class=\"data row3 col1\" >1</td>\n",
       "      <td id=\"T_d5919_row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "      <td id=\"T_d5919_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_d5919_row3_col4\" class=\"data row3 col4\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5919_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d5919_row4_col0\" class=\"data row4 col0\" >1</td>\n",
       "      <td id=\"T_d5919_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_d5919_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_d5919_row4_col3\" class=\"data row4 col3\" >1</td>\n",
       "      <td id=\"T_d5919_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5919_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d5919_row5_col0\" class=\"data row5 col0\" >1</td>\n",
       "      <td id=\"T_d5919_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "      <td id=\"T_d5919_row5_col2\" class=\"data row5 col2\" >1</td>\n",
       "      <td id=\"T_d5919_row5_col3\" class=\"data row5 col3\" >0</td>\n",
       "      <td id=\"T_d5919_row5_col4\" class=\"data row5 col4\" >0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5919_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d5919_row6_col0\" class=\"data row6 col0\" >1</td>\n",
       "      <td id=\"T_d5919_row6_col1\" class=\"data row6 col1\" >1</td>\n",
       "      <td id=\"T_d5919_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_d5919_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_d5919_row6_col4\" class=\"data row6 col4\" >0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d5919_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d5919_row7_col0\" class=\"data row7 col0\" >1</td>\n",
       "      <td id=\"T_d5919_row7_col1\" class=\"data row7 col1\" >1</td>\n",
       "      <td id=\"T_d5919_row7_col2\" class=\"data row7 col2\" >1</td>\n",
       "      <td id=\"T_d5919_row7_col3\" class=\"data row7 col3\" >1</td>\n",
       "      <td id=\"T_d5919_row7_col4\" class=\"data row7 col4\" >0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe78501c3a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#================ IF YOU WISH, YOU CAN FORMAT THE OUTPUT NICELY LIKE THIS\n",
    "import pandas\n",
    "Ynd = model(xnd).detach()\n",
    "df = pandas.DataFrame(  np.hstack ([xnd, ynd, Ynd])  , columns=['x0','x1','x2','Target output y','Predicted output Y'])\n",
    "df = df.style.format(\"{:.0f}\").format(\"{:.2f}\", subset='Predicted output Y')\n",
    "df = df.set_properties (**{'font-size':'10pt'})\n",
    "df = df.set_table_styles([dict(selector=\"th\", props=[(\"font-size\", '10pt')])])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "505fd301-8a89-4f83-ab10-d9f2f2768c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a0dbf th {\n",
       "  font-size: 10pt;\n",
       "}\n",
       "#T_a0dbf_row0_col0, #T_a0dbf_row0_col1, #T_a0dbf_row0_col2, #T_a0dbf_row1_col0, #T_a0dbf_row1_col1, #T_a0dbf_row1_col2, #T_a0dbf_row2_col0, #T_a0dbf_row2_col1, #T_a0dbf_row2_col2, #T_a0dbf_row3_col0, #T_a0dbf_row3_col1, #T_a0dbf_row3_col2, #T_a0dbf_row4_col0, #T_a0dbf_row4_col1, #T_a0dbf_row4_col2, #T_a0dbf_row5_col0, #T_a0dbf_row5_col1, #T_a0dbf_row5_col2, #T_a0dbf_row6_col0, #T_a0dbf_row6_col1, #T_a0dbf_row6_col2, #T_a0dbf_row7_col0, #T_a0dbf_row7_col1, #T_a0dbf_row7_col2 {\n",
       "  font-size: 10pt;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a0dbf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a0dbf_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_a0dbf_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_a0dbf_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a0dbf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a0dbf_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "      <td id=\"T_a0dbf_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_a0dbf_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0dbf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a0dbf_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_a0dbf_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "      <td id=\"T_a0dbf_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0dbf_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_a0dbf_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "      <td id=\"T_a0dbf_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "      <td id=\"T_a0dbf_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0dbf_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_a0dbf_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "      <td id=\"T_a0dbf_row3_col1\" class=\"data row3 col1\" >1.000000</td>\n",
       "      <td id=\"T_a0dbf_row3_col2\" class=\"data row3 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0dbf_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_a0dbf_row4_col0\" class=\"data row4 col0\" >1.000000</td>\n",
       "      <td id=\"T_a0dbf_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_a0dbf_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0dbf_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_a0dbf_row5_col0\" class=\"data row5 col0\" >1.000000</td>\n",
       "      <td id=\"T_a0dbf_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
       "      <td id=\"T_a0dbf_row5_col2\" class=\"data row5 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0dbf_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_a0dbf_row6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "      <td id=\"T_a0dbf_row6_col1\" class=\"data row6 col1\" >1.000000</td>\n",
       "      <td id=\"T_a0dbf_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a0dbf_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_a0dbf_row7_col0\" class=\"data row7 col0\" >1.000000</td>\n",
       "      <td id=\"T_a0dbf_row7_col1\" class=\"data row7 col1\" >1.000000</td>\n",
       "      <td id=\"T_a0dbf_row7_col2\" class=\"data row7 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas,IPython\n",
    "#================ pretty (...) ================\n",
    "# Pretty-prints a matrix via torch -> numpy -> pandas -> HTML -> display\n",
    "def pretty (mat):\n",
    "  if isinstance(mat, torch.Tensor):\n",
    "    mat = mat.numpy()\n",
    "  df = pandas.DataFrame(mat)\n",
    "  #df = df.style.format(\"{:.0f}\").format(\"{:.2f}\", subset='Predicted output Y')\n",
    "  df = df.style.set_properties (**{'font-size':'10pt'})\n",
    "  df = df.set_table_styles([dict(selector=\"th\", props=[(\"font-size\", '10pt')])])\n",
    "  IPython.display.display(IPython.display.HTML(df.to_html()))\n",
    "pretty (xnd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
