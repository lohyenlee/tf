{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b08904e-e3ba-4a6e-afd8-19fbda0e15cd",
   "metadata": {},
   "source": [
    "# Neural Networks in PyTorch\n",
    "## Part 11: Training a NN using the GPU\n",
    "*Yen Lee Loh, 2021-9-8, 2022-11-23*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a21ce8-4036-451c-a285-ff8b4a15c603",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade97b68-779f-40e4-a147-cdc34f1565bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import nn        # import torch.nn as nn\n",
    "import torchvision.datasets # In functional.py: patch PILLOW_VERSION--> __version__\n",
    "import torchvision.transforms\n",
    "from collections.abc import Iterable\n",
    "rng = np.random.default_rng()\n",
    "np.set_printoptions (linewidth=300)\n",
    "plt.rcParams.update ({'font.family':'serif', 'font.size':13})\n",
    "\n",
    "'''\n",
    "  gallery(xnij)\n",
    "  Display an array of grayscale images \n",
    "'''\n",
    "def gallery(xnij, cmap='viridis', labels=None, size=1):  # size is in inches\n",
    "  nmax = len(xnij)\n",
    "  cols = min(20,nmax) ; rows = (nmax+cols-1)//cols\n",
    "  wspace = 0.02 ; hspace = 0.02\n",
    "  if isinstance (labels, Iterable) or labels!=None:   # if user has supplied labels\n",
    "    hspace = .35\n",
    "    \n",
    "  fig,axs = plt.subplots (rows,cols, figsize=(cols*size*(1+wspace),rows*size*(1+hspace)), gridspec_kw={'wspace':wspace,'hspace':hspace})\n",
    "  if nmax==1: axs = np.array([[axs]])\n",
    "  axs = axs.flatten()\n",
    "  for ax in axs:\n",
    "      ax.axis ('off')\n",
    "  for n in range(nmax):\n",
    "      ax = axs[n]\n",
    "      if isinstance (cmap, Iterable) and not isinstance (cmap, str):\n",
    "        c = cmap[n]\n",
    "      else:\n",
    "        c = cmap\n",
    "      ax.imshow (xnij[n], cmap=c)\n",
    "      ax.set_aspect('equal')\n",
    "      if isinstance (labels, Iterable):\n",
    "        ax.set_title (str(labels[n]))\n",
    "\n",
    "'''\n",
    "    totalExamples,misclassifiedExamples,confusionMatrix = metrics (modelOutputs, trueOutputs)\n",
    "'''\n",
    "def metrics (Yn, yn):\n",
    "  nmax = len(yn)\n",
    "  ymax = max(yn)+1\n",
    "  confmat = np.zeros ([ymax, ymax], dtype=int)   # confmat[Y][y]\n",
    "  for n in range(nmax): confmat[yn[n], Yn[n]] += 1\n",
    "  ntot = np.sum(confmat)\n",
    "  nerr = ntot - np.trace(confmat)\n",
    "  return ntot,nerr,confmat\n",
    "\n",
    "'''\n",
    "    xT,yT,xV,yV = select (MNISTinputs, MNISToutputs, [5,6,8], [100,100,100], [200,200,200])\n",
    "\n",
    "    Given a set of inputs and outputs, \n",
    "    construct a training set consisting of the first 100 5's, 100 6's, 100 8's, \n",
    "    and a validation set consisting of the next 200 5's, 200 6's, and 200 8's.\n",
    "    If the original set has fewer than 300 5's, 6's, or 7's, raise an exception.\n",
    "'''\n",
    "def select (inputs, outputs, classes, nT, nV, shuffle=False):\n",
    "  assert len(classes) == len(nT) and len(nT) == len(nV)\n",
    "  allT = []\n",
    "  allV = []\n",
    "  for k in range(len(classes)):\n",
    "    indices, = np.where(outputs==classes[k])\n",
    "    ntot = len(indices)\n",
    "    indices = rng.choice (indices, nT[k] + nV[k], False)    # randomly choose 300\n",
    "    indicesT,indicesV = np.split (indices, [nT[k]])\n",
    "    allT += indicesT.tolist()\n",
    "    allV += indicesV.tolist()\n",
    "    print ('For class {}, given {} examples, we chose {} for training and {} for validation. '.format(classes[k], ntot, len(indicesT), len(indicesV)))\n",
    "  if shuffle:\n",
    "    rng.shuffle (allT)\n",
    "    rng.shuffle (allV)\n",
    "  return inputs[allT], outputs[allT], inputs[allV], outputs[allV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026e5586-4900-439b-bd50-3ca05c94016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================ DOWNLOAD THE MNIST-TRAIN DATASET, WHICH CONTAINS 60000 HANDWRITTEN DIGITS\n",
    "dataset = torchvision.datasets.MNIST('MNIST-TRAIN', download=True, train=True, transform=torchvision.transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=70000, shuffle=False)\n",
    "iterator = iter(loader)\n",
    "inputs,outputs = next(iterator)  # new PyTorch syntax; old syntax was iterator.next()\n",
    "inputs = inputs.squeeze()        # get rid of unnecessary dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "406842e9-1f31-4716-9fe2-c21d454433a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available() = True\n"
     ]
    }
   ],
   "source": [
    "print (\"torch.cuda.is_available() =\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be3188-a04d-4ba8-8e20-cc0248c4e618",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## 2. Load a digit pair from the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8fabab7-153d-4914-83b1-bf079dc20ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For class 3, given 6131 examples, we chose 2500 for training and 2500 for validation. \n",
      "For class 8, given 5851 examples, we chose 2500 for training and 2500 for validation. \n"
     ]
    }
   ],
   "source": [
    "class0,class1 = 3,8     #1,5\n",
    "xnijT,ynT,xnijV,ynV = select (inputs, outputs, [class0,class1], [2500,2500], [2500,2500], shuffle=True) \n",
    "xndT = xnijT.flatten (1,-1) ; yndT = (ynT.reshape (-1,1) - class0) / (class1-class0)\n",
    "xndV = xnijV.flatten (1,-1) ; yndV = (ynV.reshape (-1,1) - class0) / (class1-class0)\n",
    "_,imax,jmax = xnijT.shape\n",
    "_,dmax = xndT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b593e67f-3c2a-412f-b1e4-1eea54e737a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## 3. Train SLP on CPU and on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b7463cc-b984-4ef7-8e7e-be9f2cb159b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(xnd, ynd, model, lossFunc, epochs=10000, learningRate=0.01, lossTarget=0.0001, reportInterval=1000):\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "  model.train()                  # put model in training mode\n",
    "  for t in range(epochs):      # t is the epoch number\n",
    "    Ynd = model(xnd)             # uppercase Y = model prediction\n",
    "    loss = lossFunc(Ynd,ynd)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if t % reportInterval == 0 or t==epochs:\n",
    "      F = loss.item()\n",
    "      print('Training epoch {}/{}  \\t Loss = {:.4f}'.format(t, epochs, F))\n",
    "      if F < lossTarget:\n",
    "        print('Training epoch {}/{}  \\t Loss = {:.4f} < lossTarget\\n'.format(t, epochs, F))\n",
    "        return\n",
    "  print ('Warning: loss > lossTarget!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f76f0f4-451f-4e4a-b62c-bec94c18a43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0/10000  \t Loss = 0.7005\n",
      "Training epoch 1000/10000  \t Loss = 0.0540\n",
      "Training epoch 2000/10000  \t Loss = 0.0417\n",
      "Training epoch 3000/10000  \t Loss = 0.0335\n",
      "Training epoch 4000/10000  \t Loss = 0.0276\n",
      "Training epoch 5000/10000  \t Loss = 0.0226\n",
      "Training epoch 6000/10000  \t Loss = 0.0182\n",
      "Training epoch 7000/10000  \t Loss = 0.0142\n",
      "Training epoch 8000/10000  \t Loss = 0.0107\n",
      "Training epoch 9000/10000  \t Loss = 0.0080\n",
      "Warning: loss > lossTarget!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#================ TRAIN MODEL ON CPU\n",
    "model    = nn.Sequential(nn.Linear(dmax,1),nn.Sigmoid())\n",
    "lossFunc = nn.BCELoss()\n",
    "train (xndT, yndT, model, lossFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e712d557-8190-46ec-a64f-4e5e89ddcca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error   =    0/5000 =  0.0%    Confusion matrix = [[2500, 0], [0, 2500]]\n",
      "Validation error =  320/5000 =  6.4%    Confusion matrix = [[2345, 155], [165, 2335]]\n"
     ]
    }
   ],
   "source": [
    "#================ EVALUATE ACCURACY FOR BOTH TRAINING AND VALIDATION SETS\n",
    "model.eval()             # choose evaluation mode\n",
    "YndT = model(xndT)\n",
    "YndV = model(xndV)\n",
    "YnT = YndT.detach().numpy().round().flatten().astype(int)  # round to either 0 or 1\n",
    "ynT = yndT.detach().numpy().flatten().astype(int)          # this is already an integer\n",
    "YnV = YndV.detach().numpy().round().flatten().astype(int)  # round to either 0 or 1\n",
    "ynV = yndV.detach().numpy().flatten().astype(int)          # this is already an integer\n",
    "\n",
    "ntot,nerr,Cnn = metrics (YnT, ynT)\n",
    "print(\"Training error   = {:4d}/{:} = {:4.1f}%    Confusion matrix = {}\".format (nerr, ntot, 100*nerr/ntot, Cnn.tolist()))\n",
    "ntot,nerr,Cnn = metrics (YnV, ynV)\n",
    "print(\"Validation error = {:4d}/{:} = {:4.1f}%    Confusion matrix = {}\".format (nerr, ntot, 100*nerr/ntot, Cnn.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3b482c5-aa5c-4fbc-a90e-f5ccc7610657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0/10000  \t Loss = 0.6998\n",
      "Training epoch 1000/10000  \t Loss = 0.0529\n",
      "Training epoch 2000/10000  \t Loss = 0.0406\n",
      "Training epoch 3000/10000  \t Loss = 0.0327\n",
      "Training epoch 4000/10000  \t Loss = 0.0268\n",
      "Training epoch 5000/10000  \t Loss = 0.0219\n",
      "Training epoch 6000/10000  \t Loss = 0.0176\n",
      "Training epoch 7000/10000  \t Loss = 0.0138\n",
      "Training epoch 8000/10000  \t Loss = 0.0104\n",
      "Training epoch 9000/10000  \t Loss = 0.0078\n",
      "Warning: loss > lossTarget!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#================ TRAIN MODEL ON GPU INSTEAD\n",
    "model    = nn.Sequential(nn.Linear(dmax,1),nn.Sigmoid())\n",
    "lossFunc = nn.BCELoss()\n",
    "XNDT = xndT.cuda()\n",
    "YNDT = yndT.cuda()\n",
    "MODEL = model.cuda()\n",
    "LOSSF = lossFunc.cuda()\n",
    "train (XNDT, YNDT, MODEL, LOSSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d262a44-9d6e-426d-b09b-b3d9a81d53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODEL.cpu()\n",
    "YndT = YNDT.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1412527-fe07-433a-ba1b-dd64c3f7c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error   =    0/5000 =  0.0%    Confusion matrix = [[2500, 0], [0, 2500]]\n",
      "Validation error =  320/5000 =  6.4%    Confusion matrix = [[2345, 155], [165, 2335]]\n"
     ]
    }
   ],
   "source": [
    "#================ EVALUATE ACCURACY FOR BOTH TRAINING AND VALIDATION SETS\n",
    "model.eval()             # choose evaluation mode\n",
    "YndT = model(xndT)\n",
    "YndV = model(xndV)\n",
    "YnT = YndT.detach().numpy().round().flatten().astype(int)  # round to either 0 or 1\n",
    "ynT = yndT.detach().numpy().flatten().astype(int)          # this is already an integer\n",
    "YnV = YndV.detach().numpy().round().flatten().astype(int)  # round to either 0 or 1\n",
    "ynV = yndV.detach().numpy().flatten().astype(int)          # this is already an integer\n",
    "\n",
    "ntot,nerr,Cnn = metrics (YnT, ynT)\n",
    "print(\"Training error   = {:4d}/{:} = {:4.1f}%    Confusion matrix = {}\".format (nerr, ntot, 100*nerr/ntot, Cnn.tolist()))\n",
    "ntot,nerr,Cnn = metrics (YnV, ynV)\n",
    "print(\"Validation error = {:4d}/{:} = {:4.1f}%    Confusion matrix = {}\".format (nerr, ntot, 100*nerr/ntot, Cnn.tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7b21d-67ca-44ab-abe9-fc3016d55502",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 4. Train CNN on CPU and on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "810692f9-819f-4bed-9cac-15cca19effa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#======== TRAIN\n",
    "model = nn.Sequential(               # 28x28 ?\n",
    "  nn.Unflatten (1, (1,28,28)),       # 1x28x28\n",
    "  nn.Conv2d    (1, 8, 5, padding=2), # 1x28x28 (after conv with 5x5 kernel and 2x2 padding)\n",
    "  nn.ReLU(),\n",
    "  nn.MaxPool2d (2),                  # 1x14x14 after pooling layer with 2x2 kernel\n",
    "  nn.Conv2d    (8, 16, 5),           # 6x10x10 after conv with 5x5 kernel and no padding\n",
    "  nn.ReLU(),\n",
    "  nn.MaxPool2d (2),                  # 16x5x5\n",
    "  nn.Flatten(),    \n",
    "  nn.Linear(16*5*5,84),              # 84\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(84,1),                   # 1\n",
    "  nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65e251f3-a17a-4677-ac27-caf287ddd80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0/10000  \t Loss = 0.6933\n",
      "Training epoch 20/10000  \t Loss = 0.0739\n",
      "Training epoch 40/10000  \t Loss = 0.0214\n",
      "Training epoch 60/10000  \t Loss = 0.0079\n",
      "Training epoch 80/10000  \t Loss = 0.0021\n",
      "Training epoch 100/10000  \t Loss = 0.0006\n",
      "Training epoch 120/10000  \t Loss = 0.0002\n",
      "Training epoch 140/10000  \t Loss = 0.0001\n",
      "Training epoch 160/10000  \t Loss = 0.0001\n",
      "Training epoch 160/10000  \t Loss = 0.0001 < lossTarget\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lossFunc = nn.BCELoss()\n",
    "XNDT = xndT.cuda()\n",
    "YNDT = yndT.cuda()\n",
    "MODEL = model.cuda()\n",
    "LOSSF = lossFunc.cuda()\n",
    "train (XNDT, YNDT, MODEL, LOSSF, reportInterval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad8a466b-ec52-4567-9684-fd7844ef1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODEL.cpu()\n",
    "YndT = YNDT.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "235ae044-896f-4a5f-8cc5-381a736b23d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error   =    0/5000 =  0.0%    Confusion matrix = [[2500, 0], [0, 2500]]\n",
      "Validation error =   27/5000 =  0.5%    Confusion matrix = [[2491, 9], [18, 2482]]\n"
     ]
    }
   ],
   "source": [
    "#================ EVALUATE ACCURACY FOR BOTH TRAINING AND VALIDATION SETS\n",
    "model.eval()             # choose evaluation mode\n",
    "YndT = model(xndT)\n",
    "YndV = model(xndV)\n",
    "YnT = YndT.detach().numpy().round().flatten().astype(int)  # round to either 0 or 1\n",
    "ynT = yndT.detach().numpy().flatten().astype(int)          # this is already an integer\n",
    "YnV = YndV.detach().numpy().round().flatten().astype(int)  # round to either 0 or 1\n",
    "ynV = yndV.detach().numpy().flatten().astype(int)          # this is already an integer\n",
    "\n",
    "ntot,nerr,Cnn = metrics (YnT, ynT)\n",
    "print(\"Training error   = {:4d}/{:} = {:4.1f}%    Confusion matrix = {}\".format (nerr, ntot, 100*nerr/ntot, Cnn.tolist()))\n",
    "ntot,nerr,Cnn = metrics (YnV, ynV)\n",
    "print(\"Validation error = {:4d}/{:} = {:4.1f}%    Confusion matrix = {}\".format (nerr, ntot, 100*nerr/ntot, Cnn.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f5456-3836-4128-9b18-c507806b912d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
